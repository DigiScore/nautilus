{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Nautilus (2020)\n",
    "### composition for bass flute and Neural Net\n",
    "\n",
    "### composed by Craig Vear [ cvear@dmu.ac.uk ]\n",
    "### commissioned by Carla Rees"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hi, before we can perform this piece we need to preload the computer with the methods and the libraries for it to execute the code.\n",
    "\n",
    "This is a step-by-step guide to walk you through this process."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first thing your computer needs are the libraries. The next cell down will load these for you when you click on the round 'play' symbol on the left. Wait for it to finish before you move to the next cell. \n",
    "NB - it will generate red text and infomation. Some of this will be advice or error messages.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.0.0-alpha0 \n",
    "!pip install pydub\n",
    "!pip install pynput\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "so far, so good !?!\n",
    "\n",
    "The following code will import the functions from these libraries that you have just installed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import pretty_midi\n",
    "from tqdm import tqdm\n",
    "from numpy.random import choice\n",
    "import pickle\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from pynput import keyboard\n",
    "from nautilusTraining import SeqSelfAttention\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once we have imported all the parent code, we establish all the variables that we will be using in the code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# state all variables\n",
    "list_all_audio = glob.glob('data/audio/*.wav')\n",
    "num = len(list_all_audio)\n",
    "print (num)\n",
    "seed_rnd = random.randrange(num)\n",
    "random.seed(seed_rnd)\n",
    "random.shuffle(list_all_audio)\n",
    "print (list_all_audio)\n",
    "break_program = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we need to define the functions that will be used to work the code in realtime. These have been copied from this project - https://github.com/haryoa/note_music_generator/blob/master/Music%20Generator.ipynb a massive thank you goes out to this coder, and the general community for sharing their code and advancing the subject of machine learning."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define all classes\n",
    "\n",
    "class NoteTokenizer:\n",
    "    def __init__(self):\n",
    "        self.notes_to_index = {}\n",
    "        self.index_to_notes = {}\n",
    "        self.num_of_word = 0\n",
    "        self.unique_word = 0\n",
    "        self.notes_freq = {}\n",
    "\n",
    "\n",
    "def piano_roll_to_pretty_midi(piano_roll, fs=100, program=0):\n",
    "    '''Convert a Piano Roll array into a PrettyMidi object\n",
    "     with a single instrument.\n",
    "    Parameters\n",
    "    ----------\n",
    "    piano_roll : np.ndarray, shape=(128,frames), dtype=int\n",
    "        Piano roll of one instrument\n",
    "    fs : int\n",
    "        Sampling frequency of the columns, i.e. each column is spaced apart\n",
    "        by ``1./fs`` seconds.\n",
    "    program : int\n",
    "        The program number of the instrument.\n",
    "    Returns\n",
    "    -------\n",
    "    midi_object : pretty_midi.PrettyMIDI\n",
    "        A pretty_midi.PrettyMIDI class instance describing\n",
    "        the piano roll.\n",
    "    '''\n",
    "    notes, frames = piano_roll.shape\n",
    "    pm = pretty_midi.PrettyMIDI(initial_tempo=20)\n",
    "    instrument = pretty_midi.Instrument(program=program)\n",
    "\n",
    "    # pad 1 column of zeros so we can acknowledge inital and ending events\n",
    "    piano_roll = np.pad(piano_roll, [(0, 0), (1, 1)], 'constant')\n",
    "\n",
    "    # use changes in velocities to find note on / note off events\n",
    "    velocity_changes = np.nonzero(np.diff(piano_roll).T)\n",
    "\n",
    "    # keep track on velocities and note on times\n",
    "    prev_velocities = np.zeros(notes, dtype=int)\n",
    "    note_on_time = np.zeros(notes)\n",
    "\n",
    "    for time, note in zip(*velocity_changes):\n",
    "        # use time + 1 because of padding above\n",
    "        velocity = piano_roll[note, time + 1]\n",
    "        time = time / fs\n",
    "        if velocity > 0:\n",
    "            if prev_velocities[note] == 0:\n",
    "                note_on_time[note] = time\n",
    "                prev_velocities[note] = velocity\n",
    "        else:\n",
    "            pm_note = pretty_midi.Note(\n",
    "                velocity=prev_velocities[note],\n",
    "                pitch=note,\n",
    "                start=note_on_time[note] * 12,\n",
    "                end=time * 12)\n",
    "            instrument.notes.append(pm_note)\n",
    "            prev_velocities[note] = 0\n",
    "    pm.instruments.append(instrument)\n",
    "    return pm\n",
    "\n",
    "\n",
    "def generate_batch_song(list_all_midi, batch_music=16, start_index=0, fs=30, seq_len=50, use_tqdm=False):\n",
    "    \"\"\"\n",
    "    Generate Batch music that will be used to be input and output of the neural network\n",
    "    Parameters\n",
    "    ==========\n",
    "    list_all_midi : list\n",
    "      List of midi files\n",
    "    batch_music : int\n",
    "      A number of music in one batch\n",
    "    start_index : int\n",
    "      The start index to be batched in list_all_midi\n",
    "    fs : int\n",
    "      Sampling frequency of the columns, i.e. each column is spaced apart\n",
    "        by ``1./fs`` seconds.\n",
    "    seq_len : int\n",
    "      The sequence length of the music to be input of neural network\n",
    "    use_tqdm : bool\n",
    "      Whether to use tqdm or not in the function\n",
    "    Returns\n",
    "    =======\n",
    "    Tuple of input and target neural network\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(list_all_midi) >= batch_music\n",
    "    dict_time_notes = generate_dict_time_notes(list_all_midi, batch_music, start_index, fs, use_tqdm=use_tqdm)\n",
    "\n",
    "    list_musics = process_notes_in_song(dict_time_notes, seq_len)\n",
    "    collected_list_input, collected_list_target = [], []\n",
    "\n",
    "    for music in list_musics:\n",
    "        list_training, list_target = generate_input_and_target(music, seq_len)\n",
    "        collected_list_input += list_training\n",
    "        collected_list_target += list_target\n",
    "    return collected_list_input, collected_list_target\n",
    "\n",
    "\n",
    "def generate_dict_time_notes(list_all_midi, batch_song=16, start_index=0, fs=30, use_tqdm=True):\n",
    "    \"\"\" Generate map (dictionary) of music ( in index ) to piano_roll (in np.array)\n",
    "    Parameters\n",
    "    ==========\n",
    "    list_all_midi : list\n",
    "        List of midi files\n",
    "    batch_music : int\n",
    "      A number of music in one batch\n",
    "    start_index : int\n",
    "      The start index to be batched in list_all_midi\n",
    "    fs : int\n",
    "      Sampling frequency of the columns, i.e. each column is spaced apart\n",
    "        by ``1./fs`` seconds.\n",
    "    use_tqdm : bool\n",
    "      Whether to use tqdm or not in the function\n",
    "    Returns\n",
    "    =======\n",
    "    dictionary of music to piano_roll (in np.array)\n",
    "    \"\"\"\n",
    "    assert len(list_all_midi) >= batch_song\n",
    "\n",
    "    dict_time_notes = {}\n",
    "    process_tqdm_midi = tqdm(\n",
    "        range(start_index, min(start_index + batch_song, len(list_all_midi)))) if use_tqdm else range(start_index, min(\n",
    "        start_index + batch_song, len(list_all_midi)))\n",
    "    for i in process_tqdm_midi:\n",
    "        midi_file_name = list_all_midi[i]\n",
    "        if use_tqdm:\n",
    "            process_tqdm_midi.set_description(\"Processing {}\".format(midi_file_name))\n",
    "        try:  # Handle exception on malformat MIDI files\n",
    "            midi_pretty_format = pretty_midi.PrettyMIDI(midi_file_name)\n",
    "            piano_midi = midi_pretty_format.instruments[0]  # Get the piano channels\n",
    "            piano_roll = piano_midi.get_piano_roll(fs=fs)\n",
    "            dict_time_notes[i] = piano_roll\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"broken file : {}\".format(midi_file_name))\n",
    "            pass\n",
    "    return dict_time_notes\n",
    "\n",
    "\n",
    "def generate_input_and_target(dict_keys_time, seq_len=50):\n",
    "    \"\"\" Generate input and the target of our deep learning for one music.\n",
    "    Parameters\n",
    "    ==========\n",
    "    dict_keys_time : dict\n",
    "      Dictionary of timestep and notes\n",
    "    seq_len : int\n",
    "      The length of the sequence\n",
    "    Returns\n",
    "    =======\n",
    "    Tuple of list of input and list of target of neural network.\n",
    "    \"\"\"\n",
    "    # Get the start time and end time\n",
    "    start_time, end_time = list(dict_keys_time.keys())[0], list(dict_keys_time.keys())[-1]\n",
    "    list_training, list_target = [], []\n",
    "    for index_enum, time in enumerate(range(start_time, end_time)):\n",
    "        list_append_training, list_append_target = [], []\n",
    "        start_iterate = 0\n",
    "        flag_target_append = False  # flag to append the test list\n",
    "        if index_enum < seq_len:\n",
    "            start_iterate = seq_len - index_enum - 1\n",
    "            for i in range(start_iterate):  # add 'e' to the seq list.\n",
    "                list_append_training.append('e')\n",
    "                flag_target_append = True\n",
    "\n",
    "        for i in range(start_iterate, seq_len):\n",
    "            index_enum = time - (seq_len - i - 1)\n",
    "            if index_enum in dict_keys_time:\n",
    "                list_append_training.append(','.join(str(x) for x in dict_keys_time[index_enum]))\n",
    "            else:\n",
    "                list_append_training.append('e')\n",
    "\n",
    "        # add time + 1 to the list_append_target\n",
    "        if time + 1 in dict_keys_time:\n",
    "            list_append_target.append(','.join(str(x) for x in dict_keys_time[time + 1]))\n",
    "        else:\n",
    "            list_append_target.append('e')\n",
    "        list_training.append(list_append_training)\n",
    "        list_target.append(list_append_target)\n",
    "    return list_training, list_target\n",
    "\n",
    "\n",
    "def process_notes_in_song(dict_time_notes, seq_len=50):\n",
    "    \"\"\"\n",
    "    Iterate the dict of piano rolls into dictionary of timesteps and note played\n",
    "    Parameters\n",
    "    ==========\n",
    "    dict_time_notes : dict\n",
    "      dict contains index of music ( in index ) to piano_roll (in np.array)\n",
    "    seq_len : int\n",
    "      Length of the sequence\n",
    "    Returns\n",
    "    =======\n",
    "    Dict of timesteps and note played\n",
    "    \"\"\"\n",
    "    list_of_dict_keys_time = []\n",
    "\n",
    "    for key in dict_time_notes:\n",
    "        sample = dict_time_notes[key]\n",
    "        times = np.unique(np.where(sample > 0)[1])\n",
    "        index = np.where(sample > 0)\n",
    "        dict_keys_time = {}\n",
    "\n",
    "        for time in times:\n",
    "            index_where = np.where(index[1] == time)\n",
    "            notes = index[0][index_where]\n",
    "            dict_keys_time[time] = notes\n",
    "        list_of_dict_keys_time.append(dict_keys_time)\n",
    "    return list_of_dict_keys_time\n",
    "\n",
    "\n",
    "def generate_from_random(unique_notes, seq_len=50):\n",
    "    generate = np.random.randint(0, unique_notes, seq_len).tolist()\n",
    "    return generate\n",
    "\n",
    "\n",
    "def generate_from_one_note(note_tokenizer, new_notes='35'):\n",
    "    generate = [note_tokenizer.notes_to_index['e'] for i in range(49)]\n",
    "    generate += [note_tokenizer.notes_to_index[new_notes]]\n",
    "    return generate\n",
    "\n",
    "\n",
    "def generate_notes(generate, model, unique_notes, max_generated=1000, seq_len=50):\n",
    "  for i in tqdm(range(max_generated), desc='genrt'):\n",
    "    test_input = np.array([generate])[:,i:i+seq_len]\n",
    "    predicted_note = model.predict(test_input)\n",
    "    random_note_pred = choice(unique_notes+1, 1, replace=False, p=predicted_note[0])\n",
    "    generate.append(random_note_pred[0])\n",
    "  return generate\n",
    "\n",
    "\n",
    "def write_midi_file_from_generated(generate, midi_file_name = \"result.mid\", start_index=49, fs=8, max_generated=1000):\n",
    "  note_string = [note_tokenizer.index_to_notes[ind_note] for ind_note in generate]\n",
    "  array_piano_roll = np.zeros((128,max_generated+1), dtype=np.int16)\n",
    "  for index, note in enumerate(note_string[start_index:]):\n",
    "    if note == 'e':\n",
    "      pass\n",
    "    else:\n",
    "      splitted_note = note.split(',')\n",
    "      for j in splitted_note:\n",
    "        array_piano_roll[int(j),index] = 1\n",
    "  generate_to_midi = piano_roll_to_pretty_midi(array_piano_roll, fs=fs)\n",
    "  print(\"Tempo {}\".format(generate_to_midi.estimate_tempo()))\n",
    "  for note in generate_to_midi.instruments[0].notes:\n",
    "    note.velocity = 100\n",
    "  generate_to_midi.write(midi_file_name)\n",
    "\n",
    "\n",
    "def carla_rnd():\n",
    "    with open('training/data/carlaDNA-v9.csv', newline='') as csvfile:\n",
    "        data = list(csv.reader(csvfile))\n",
    "        length = len(data)\n",
    "        rnd = random.randrange(length)\n",
    "        starting_note = data[rnd]\n",
    "        print(starting_note)\n",
    "        return starting_note\n",
    "\n",
    "\n",
    "def speed_change(sound, vol):\n",
    "    # randomly generate playback speed 0.3-0.5\n",
    "    rnd_speed = random.randrange(3, 5)\n",
    "    speed = rnd_speed / 10\n",
    "    print ('change of speed = ', speed)\n",
    "    print('change of gain = ', vol)\n",
    "    # Manually override the frame_rate. This tells the computer how many\n",
    "    # samples to play per second\n",
    "    sound_with_altered_frame_rate = sound._spawn(sound.raw_data, overrides={\n",
    "         \"frame_rate\": int(sound.frame_rate * speed)\n",
    "      })\n",
    "    # change gain\n",
    "    sound_with_altered_frame_rate_and_gain = sound_with_altered_frame_rate.apply_gain(vol)\n",
    "    # convert the sound with altered frame rate to a standard frame rate\n",
    "    # so that regular playback programs will work right. They often only\n",
    "    # know how to play audio at standard frame rate (like 44.1k)\n",
    "    return sound_with_altered_frame_rate_and_gain.set_frame_rate(sound.frame_rate)\n",
    "\n",
    "\n",
    "def on_press(key):\n",
    "    global break_program\n",
    "    if key == keyboard.Key.space:\n",
    "        print ('end pressed')\n",
    "        break_program = True\n",
    "        return False\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "OK - so you've made it this far unscathed. Next is the working code. This will start the composition. The first thing it will do is to generate a random seed note from Carla's original improvisation. It will then use this seed to generate a score individual for this version of the composition. This is generated using a Neural Network (think mini-music-mind) trained on jazz improvsations. In a poetic sense, the Neural Net riffs and improvises with this signle seed note to create a brand new version of this piece. \n",
    "\n",
    "Once it has generated this sequence of notes, it will package it as a music core, export it to Muse Score, which will then open it up for you to read.\n",
    "\n",
    "At the same time, it will also start performing its own improvisation based on Carla's original improvisation.\n",
    "\n",
    "The aim is to perform with this other musician. It is not listening to you, but is travelling with you as you navigate the depths of this ocean of sound.\n",
    "\n",
    "When you have reached the end of your score, press the Space Bar and the computer will draw its improvisation to a close.\n",
    "  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# build model from trained files\n",
    "model = tf.keras.models.load_model('data/epochs4-long-model_ep4.h5', custom_objects=SeqSelfAttention.get_custom_objects())\n",
    "note_tokenizer  = pickle.load(open(\"data/epochs4-long-tokenizer.p\", \"rb\"))\n",
    "\n",
    "# generate midi files\n",
    "max_generate = 100\n",
    "unique_notes = note_tokenizer.unique_word\n",
    "seq_len = 50\n",
    "\n",
    "#  generation from a single Carla DNA note\n",
    "starting_note = \"\".join(carla_rnd())\n",
    "generate = generate_from_one_note(note_tokenizer, starting_note)\n",
    "\n",
    "generate = generate_notes(generate, model, unique_notes, max_generate, seq_len)\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "midi_file_name = \"data/output/nautilus\" + current_time + \".mid\"\n",
    "print (midi_file_name)\n",
    "write_midi_file_from_generated(generate, midi_file_name, start_index=seq_len-1, fs=8, max_generated = max_generate)\n",
    "\n",
    "# open midi file in Musescore here\n",
    "openmidi = str('open '+ midi_file_name)\n",
    "print (openmidi)\n",
    "os.system(openmidi)\n",
    "\n",
    "# this is where the progran starts\n",
    "with keyboard.Listener(on_press=on_press) as listener:\n",
    "    while break_program == False:\n",
    "        # select file from random list\n",
    "        rnd_file = random.randrange(num)\n",
    "        sound_file = list_all_audio[rnd_file]\n",
    "        print ('sound file = ', sound_file)\n",
    "        sound = AudioSegment.from_wav(sound_file)\n",
    "        # gain structure?\n",
    "        gain_rnd = random.randrange(2)\n",
    "        gain = gain_rnd + 1\n",
    "        # play (sound)\n",
    "        new_sound = speed_change(sound, gain)\n",
    "        length = new_sound.duration_seconds\n",
    "        print('length = ', length)\n",
    "        fade_sound = new_sound.fade_in(1000).fade_out(500)\n",
    "        play(fade_sound)\n",
    "        sleep(length)\n",
    "    listener.join()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}